{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Алгоритмы анализа данных\n",
    "\n",
    "\n",
    "> [Geek University Data Analytics](https://geekbrains.ru/)\n",
    "\n",
    "##  [ Урок 2. Масштабирование признаков. L1- и L2-регуляризация. Стохастический градиентный спуск](https://geekbrains.ru/lessons/108932/)\n",
    "\n",
    "## Задание:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Домашнее задание</b>\n",
    "\n",
    "1.У вас, с прошлого урока, имеются реализации расчёта среднеквадратичной ошибки и её градиента для линейнй регрессии с коэффициентами при факторах(w) и свободным коэффициентам.\n",
    "\n",
    "```python\n",
    "class linear_regression:\n",
    "    def _mserror(self, X, y_real):\n",
    "        #рассчёт среднеквадратичной ошибки\n",
    "        y = X.dot(self.w.T)+self.w0\n",
    "        return np.sum((y - y_real)**2) / y_real.shape[0]\n",
    "    def _mserror_grad(self, X, y_real):\n",
    "        #рассчёт градиента ошибки.\n",
    "        #2*delta.T.dot(X)/y_real.shape[0] - градиент по коэффициентам при факторах\n",
    "        #np.sum(2*delta)/y_real.shape[0] - производная(градиент) при нулевом коэффициенте\n",
    "        delta=(X.dot(self.w.T)+self.w0-y_real)\n",
    "        return 2*delta.T.dot(X)/y_real.shape[0], np.sum(2*delta)/y_real.shape[0]\n",
    "```\n",
    "\n",
    "В этом задании вы должны модифицировать реализацию рассчёта среднеквадратичной ошибки и рассчёта её производной, так, чтобы с к среднеквадратичной ошибке добавлялась l2 регулярязационная поправка: $ +c*\\sum \\limits _{j}  w_{j}^2 $ а к градиенту- ссответствующее выражение для градиента регулярязационной поправки. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Изначальный класс:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_regression:\n",
    "    def __init__(self, eta = 0.9, max_iter = 1e4, min_weight_dist = 1e-8):\n",
    "        self.eta = eta\n",
    "        self.max_iter = max_iter\n",
    "        self.min_weight_dist = min_weight_dist\n",
    "    def _mserror(self, X, y_real):\n",
    "        #рассчёт среднеквадратичной ошибки\n",
    "        y = X.dot(self.w.T)+self.w0\n",
    "        return np.sum((y - y_real)**2) / y_real.shape[0]\n",
    "    def _mserror_grad(self, X, y_real):\n",
    "        #рассчёт градиента ошибки.\n",
    "        #2*delta.T.dot(X)/y_real.shape[0] - градиент по коэффициентам при факторах\n",
    "        #np.sum(2*delta)/y_real.shape[0] - производная(градиент) при нулевом коэффициенте\n",
    "        delta=(X.dot(self.w.T)+self.w0-y_real)\n",
    "        return 2*delta.T.dot(X)/y_real.shape[0], np.sum(2*delta)/y_real.shape[0]\n",
    "    def _optimize(self, X, Y):\n",
    "        #оптимизация коэффициентов\n",
    "        iter_num = 0\n",
    "        weight_dist = np.inf\n",
    "        self.w = np.zeros((1, X.shape[1]))\n",
    "        self.w0=0\n",
    "        while weight_dist > self.min_weight_dist and iter_num < self.max_iter:\n",
    "            gr_w, gr_w0=self._mserror_grad(X, Y)\n",
    "            if iter_num==0:\n",
    "                #Чтобы eta адаптировалась к порядку градиента, делим на l2 норму градиента в нуле\n",
    "                eta=self.eta/np.sqrt(np.linalg.norm(gr_w)**2+(gr_w0)**2)\n",
    "            new_w = self.w - eta * gr_w\n",
    "            new_w0= self.w0 - eta * gr_w0\n",
    "            weight_dist = np.sqrt(np.linalg.norm(new_w - self.w)**2+(new_w0 - self.w0)**2)\n",
    "            iter_num += 1\n",
    "            self.w = new_w\n",
    "            self.w0 = new_w0\n",
    "    def fit(self, X, Y):\n",
    "        if Y.ndim==1:\n",
    "            Y=Y[:, np.newaxis]\n",
    "        self._optimize(X, Y)\n",
    "    def predict(self, X):\n",
    "        return (X.dot(self.w.T)+self.w0).flatten()\n",
    "    def test(self, X, Y):\n",
    "        if Y.ndim==1:\n",
    "            Y=Y[:, np.newaxis]\n",
    "        return self._mserror(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переназначаем класс. Для этого нужно ввести лямбду. Лямбда взята из [примера](https://github.com/annulet/DS_Algorithms/blob/master/hw_2.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class new_lin_reg(linear_regression):\n",
    "    def _mserror(self, X, y_real, lambda_=1e-8):\n",
    "        y = X.dot(self.w.T)+self.w0\n",
    "        res = np.sum((y - y_real)**2) / y_real.shape[0] + lambda_* self.w**2\n",
    "        return res   \n",
    "    \n",
    "    def _mserror_grad(self, X, y_real):\n",
    "        '''\n",
    "        Рассчёт градиента ошибки. Градиент ошибки - по сути производная от функции, \n",
    "        описывающей ошибку.\n",
    "        '''\n",
    "        delta =(X.dot(self.w.T)+self.w0-y_real)\n",
    "        O1 = 2*delta.T.dot(X)/y_real.shape[0] \n",
    "        O0 = np.sum(2*delta)/y_real.shape[0]\n",
    "        ## reg_grad = \n",
    "        \n",
    "        return O1, O0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я понимаю, что здесь должна быть формула, показывающая скорость изменения регулизационной ошибки. Но как её описать - не смог придумать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.На основе этих функций создайте свою регуляризированную полиномиальную регрессию и опробуйте на одном из примеров построения полиномиальной модели из этого урока. <br>\n",
    "\n",
    "\n",
    "<i><b>Пояснение:</b> Для этого Вам достаточно создать класс, который наследуется от класса polynomial_regression из данного урока, и переопределить в нём методы mserror, mserror_grad(под переопределением подразумевается создание на новом классе методов с таким же названием). </i>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0772939735436267"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shift=np.random.uniform(0, 100)\n",
    "shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Возьмем 2 признака и 1000 объектов\n",
    "n_features = 4\n",
    "n_objects = 1000\n",
    "\n",
    "# сгенерируем вектор истинных весов\n",
    "w_true = np.random.normal(size=(1, n_features ))\n",
    "\n",
    "# сгенерируем матрицу X, вычислим Y с добавлением случайного шума\n",
    "X = np.random.uniform(-7, 7, (n_objects, n_features))\n",
    "Y = X.dot(w_true.T) + np.random.normal(0, 0.5, size=(n_objects, 1))\n",
    "\n",
    "# возьмем нулевые начальные веса\n",
    "w = np.zeros((1, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25529714, 0.25529716, 0.25529714, 0.25529714]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shift=np.random.uniform(0, 100)\n",
    "Y_shift=Y+shift\n",
    "lr=new_lin_reg()\n",
    "lr.fit(X, Y_shift)\n",
    "lr.test(X, Y_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41.16315379691662, 41.17004064787974)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shift, lr.w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.34035137,  1.32720351, -0.07548054,  0.52864583]]),\n",
       " array([[-0.34842471,  1.32168038, -0.08148227,  0.52951858]]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.w, w_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Заметки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Статья на Хабре](https://habr.com/ru/company/nix/blog/425907/#масштабирование)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Статья про L1, L2 регулизацию](https://craftappmobile.com/l1-%D0%B8-l2-%D1%80%D0%B5%D0%B3%D1%83%D0%BB%D1%8F%D1%80%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F-%D0%B4%D0%BB%D1%8F-%D0%BB%D0%BE%D0%B3%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B9-%D1%80/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
